{"ast":null,"code":"import { exporter, recursive } from 'ipfs-unixfs-exporter';\nimport errCode from 'err-code';\nimport { normalizeCidPath } from '../utils.js';\nimport { withTimeoutOption } from 'ipfs-core-utils/with-timeout-option';\nimport { CID } from 'multiformats/cid';\nimport { pack } from 'it-tar';\nimport { pipe } from 'it-pipe';\nimport Pako from 'pako';\nimport toBuffer from 'it-to-buffer'; // https://www.gnu.org/software/gzip/manual/gzip.html\n\nconst DEFAULT_COMPRESSION_LEVEL = 6;\n/**\n * @typedef {object} Context\n * @property {import('ipfs-repo').IPFSRepo} repo\n * @property {import('../types').Preload} preload\n *\n * @param {Context} context\n */\n\nexport function createGet(_ref) {\n  let {\n    repo,\n    preload\n  } = _ref;\n\n  /**\n   * @type {import('ipfs-core-types/src/root').API<{}>[\"get\"]}\n   */\n  async function* get(ipfsPath) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    if (options.compressionLevel != null && (options.compressionLevel < -1 || options.compressionLevel > 9)) {\n      throw errCode(new Error('Compression level must be between -1 and 9'), 'ERR_INVALID_PARAMS');\n    }\n\n    if (options.preload !== false) {\n      let pathComponents;\n\n      try {\n        pathComponents = normalizeCidPath(ipfsPath).split('/');\n      } catch (\n      /** @type {any} */\n      err) {\n        throw errCode(err, 'ERR_INVALID_PATH');\n      }\n\n      preload(CID.parse(pathComponents[0]));\n    }\n\n    const ipfsPathOrCid = CID.asCID(ipfsPath) || ipfsPath;\n    const file = await exporter(ipfsPathOrCid, repo.blocks, options);\n\n    if (file.type === 'file' || file.type === 'raw') {\n      const args = [];\n\n      if (!options.compress || options.archive === true) {\n        args.push([{\n          header: {\n            name: file.path,\n            mode: file.type === 'file' && file.unixfs.mode,\n            mtime: file.type === 'file' && file.unixfs.mtime ? new Date(file.unixfs.mtime.secs * 1000) : undefined,\n            size: file.size,\n            type: 'file'\n          },\n          body: file.content()\n        }], pack());\n      } else {\n        args.push(file.content);\n      }\n\n      if (options.compress) {\n        args.push(\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        async function* (source) {\n          const buf = await toBuffer(source);\n          yield Pako.gzip(buf, {\n            level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n          });\n        });\n      } // @ts-expect-error cannot derive type\n\n\n      yield* pipe(...args);\n      return;\n    }\n\n    if (file.type === 'directory') {\n      /** @type {any[]} */\n      const args = [recursive(ipfsPathOrCid, repo.blocks, options),\n      /**\n       * @param {AsyncIterable<import('ipfs-unixfs-exporter').UnixFSEntry>} source\n       */\n      async function* (source) {\n        for await (const entry of source) {\n          /** @type {import('it-tar').TarImportCandidate} */\n          const output = {\n            header: {\n              name: entry.path,\n              size: entry.size\n            }\n          };\n\n          if (entry.type === 'file') {\n            output.header.type = 'file';\n            output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n            output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n            output.body = entry.content();\n          } else if (entry.type === 'raw') {\n            output.header.type = 'file';\n            output.body = entry.content();\n          } else if (entry.type === 'directory') {\n            output.header.type = 'directory';\n            output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n            output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n          } else {\n            throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n          }\n\n          yield output;\n        }\n      }, pack()];\n\n      if (options.compress) {\n        if (!options.archive) {\n          throw errCode(new Error('file is not regular'), 'ERR_INVALID_PATH');\n        }\n\n        if (options.compress) {\n          args.push(\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          async function* (source) {\n            const buf = await toBuffer(source);\n            yield Pako.gzip(buf, {\n              level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n            });\n          });\n        }\n      } // @ts-expect-error cannot derive type\n\n\n      yield* pipe(...args);\n      return;\n    }\n\n    throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n  }\n\n  return withTimeoutOption(get);\n}","map":{"version":3,"sources":["C:/Users/Akshay Mishra/OneDrive/Desktop/twitter-clone-dapp/node_modules/ipfs-core/src/components/get.js"],"names":["exporter","recursive","errCode","normalizeCidPath","withTimeoutOption","CID","pack","pipe","Pako","toBuffer","DEFAULT_COMPRESSION_LEVEL","createGet","repo","preload","get","ipfsPath","options","compressionLevel","Error","pathComponents","split","err","parse","ipfsPathOrCid","asCID","file","blocks","type","args","compress","archive","push","header","name","path","mode","unixfs","mtime","Date","secs","undefined","size","body","content","source","buf","gzip","level","entry","output"],"mappings":"AAAA,SAASA,QAAT,EAAmBC,SAAnB,QAAoC,sBAApC;AACA,OAAOC,OAAP,MAAoB,UAApB;AACA,SAASC,gBAAT,QAAiC,aAAjC;AACA,SAASC,iBAAT,QAAkC,qCAAlC;AACA,SAASC,GAAT,QAAoB,kBAApB;AACA,SAASC,IAAT,QAAqB,QAArB;AACA,SAASC,IAAT,QAAqB,SAArB;AACA,OAAOC,IAAP,MAAiB,MAAjB;AACA,OAAOC,QAAP,MAAqB,cAArB,C,CAEA;;AACA,MAAMC,yBAAyB,GAAG,CAAlC;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,SAAT,OAAuC;AAAA,MAAnB;AAAEC,IAAAA,IAAF;AAAQC,IAAAA;AAAR,GAAmB;;AAC5C;AACF;AACA;AACE,kBAAiBC,GAAjB,CAAsBC,QAAtB,EAA8C;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAC5C,QAAIA,OAAO,CAACC,gBAAR,IAA4B,IAA5B,KAAqCD,OAAO,CAACC,gBAAR,GAA2B,CAAC,CAA5B,IAAiCD,OAAO,CAACC,gBAAR,GAA2B,CAAjG,CAAJ,EAAyG;AACvG,YAAMf,OAAO,CAAC,IAAIgB,KAAJ,CAAU,4CAAV,CAAD,EAA0D,oBAA1D,CAAb;AACD;;AAED,QAAIF,OAAO,CAACH,OAAR,KAAoB,KAAxB,EAA+B;AAC7B,UAAIM,cAAJ;;AAEA,UAAI;AACFA,QAAAA,cAAc,GAAGhB,gBAAgB,CAACY,QAAD,CAAhB,CAA2BK,KAA3B,CAAiC,GAAjC,CAAjB;AACD,OAFD,CAEE;AAAO;AAAmBC,MAAAA,GAA1B,EAA+B;AAC/B,cAAMnB,OAAO,CAACmB,GAAD,EAAM,kBAAN,CAAb;AACD;;AAEDR,MAAAA,OAAO,CAACR,GAAG,CAACiB,KAAJ,CAAUH,cAAc,CAAC,CAAD,CAAxB,CAAD,CAAP;AACD;;AAED,UAAMI,aAAa,GAAGlB,GAAG,CAACmB,KAAJ,CAAUT,QAAV,KAAuBA,QAA7C;AACA,UAAMU,IAAI,GAAG,MAAMzB,QAAQ,CAACuB,aAAD,EAAgBX,IAAI,CAACc,MAArB,EAA6BV,OAA7B,CAA3B;;AAEA,QAAIS,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACE,IAAL,KAAc,KAA1C,EAAiD;AAC/C,YAAMC,IAAI,GAAG,EAAb;;AAEA,UAAI,CAACZ,OAAO,CAACa,QAAT,IAAqBb,OAAO,CAACc,OAAR,KAAoB,IAA7C,EAAmD;AACjDF,QAAAA,IAAI,CAACG,IAAL,CAAU,CAAC;AACTC,UAAAA,MAAM,EAAE;AACNC,YAAAA,IAAI,EAAER,IAAI,CAACS,IADL;AAENC,YAAAA,IAAI,EAAEV,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACW,MAAL,CAAYD,IAFpC;AAGNE,YAAAA,KAAK,EAAEZ,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACW,MAAL,CAAYC,KAApC,GAA4C,IAAIC,IAAJ,CAASb,IAAI,CAACW,MAAL,CAAYC,KAAZ,CAAkBE,IAAlB,GAAyB,IAAlC,CAA5C,GAAsFC,SAHvF;AAINC,YAAAA,IAAI,EAAEhB,IAAI,CAACgB,IAJL;AAKNd,YAAAA,IAAI,EAAE;AALA,WADC;AAQTe,UAAAA,IAAI,EAAEjB,IAAI,CAACkB,OAAL;AARG,SAAD,CAAV,EAUArC,IAAI,EAVJ;AAYD,OAbD,MAaO;AACLsB,QAAAA,IAAI,CAACG,IAAL,CACEN,IAAI,CAACkB,OADP;AAGD;;AAED,UAAI3B,OAAO,CAACa,QAAZ,EAAsB;AACpBD,QAAAA,IAAI,CAACG,IAAL;AACE;AACV;AACA;AACU,yBAAkBa,MAAlB,EAA0B;AACxB,gBAAMC,GAAG,GAAG,MAAMpC,QAAQ,CAACmC,MAAD,CAA1B;AAEA,gBAAMpC,IAAI,CAACsC,IAAL,CAAUD,GAAV,EAAe;AACnBE,YAAAA,KAAK,EAAE/B,OAAO,CAACC,gBAAR,IAA4BP;AADhB,WAAf,CAAN;AAGD,SAVH;AAYD,OAnC8C,CAqC/C;;;AACA,aAAQH,IAAI,CAAC,GAAGqB,IAAJ,CAAZ;AAEA;AACD;;AAED,QAAIH,IAAI,CAACE,IAAL,KAAc,WAAlB,EAA+B;AAC7B;AACA,YAAMC,IAAI,GAAG,CACX3B,SAAS,CAACsB,aAAD,EAAgBX,IAAI,CAACc,MAArB,EAA6BV,OAA7B,CADE;AAEX;AACR;AACA;AACQ,uBAAkB4B,MAAlB,EAA0B;AACxB,mBAAW,MAAMI,KAAjB,IAA0BJ,MAA1B,EAAkC;AAChC;AACA,gBAAMK,MAAM,GAAG;AACbjB,YAAAA,MAAM,EAAE;AACNC,cAAAA,IAAI,EAAEe,KAAK,CAACd,IADN;AAENO,cAAAA,IAAI,EAAEO,KAAK,CAACP;AAFN;AADK,WAAf;;AAOA,cAAIO,KAAK,CAACrB,IAAN,KAAe,MAAnB,EAA2B;AACzBsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,MAArB;AACAsB,YAAAA,MAAM,CAACjB,MAAP,CAAcG,IAAd,GAAqBa,KAAK,CAACZ,MAAN,CAAaD,IAAb,IAAqB,IAArB,GAA4Ba,KAAK,CAACZ,MAAN,CAAaD,IAAzC,GAAgDK,SAArE;AACAS,YAAAA,MAAM,CAACjB,MAAP,CAAcK,KAAd,GAAsBW,KAAK,CAACZ,MAAN,CAAaC,KAAb,GAAqB,IAAIC,IAAJ,CAASU,KAAK,CAACZ,MAAN,CAAaC,KAAb,CAAmBE,IAAnB,GAA0B,IAAnC,CAArB,GAAgEC,SAAtF;AACAS,YAAAA,MAAM,CAACP,IAAP,GAAcM,KAAK,CAACL,OAAN,EAAd;AACD,WALD,MAKO,IAAIK,KAAK,CAACrB,IAAN,KAAe,KAAnB,EAA0B;AAC/BsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,MAArB;AACAsB,YAAAA,MAAM,CAACP,IAAP,GAAcM,KAAK,CAACL,OAAN,EAAd;AACD,WAHM,MAGA,IAAIK,KAAK,CAACrB,IAAN,KAAe,WAAnB,EAAgC;AACrCsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,WAArB;AACAsB,YAAAA,MAAM,CAACjB,MAAP,CAAcG,IAAd,GAAqBa,KAAK,CAACZ,MAAN,CAAaD,IAAb,IAAqB,IAArB,GAA4Ba,KAAK,CAACZ,MAAN,CAAaD,IAAzC,GAAgDK,SAArE;AACAS,YAAAA,MAAM,CAACjB,MAAP,CAAcK,KAAd,GAAsBW,KAAK,CAACZ,MAAN,CAAaC,KAAb,GAAqB,IAAIC,IAAJ,CAASU,KAAK,CAACZ,MAAN,CAAaC,KAAb,CAAmBE,IAAnB,GAA0B,IAAnC,CAArB,GAAgEC,SAAtF;AACD,WAJM,MAIA;AACL,kBAAMtC,OAAO,CAAC,IAAIgB,KAAJ,CAAU,mBAAV,CAAD,EAAiC,gBAAjC,CAAb;AACD;;AAED,gBAAM+B,MAAN;AACD;AACF,OAjCU,EAkCX3C,IAAI,EAlCO,CAAb;;AAqCA,UAAIU,OAAO,CAACa,QAAZ,EAAsB;AACpB,YAAI,CAACb,OAAO,CAACc,OAAb,EAAsB;AACpB,gBAAM5B,OAAO,CAAC,IAAIgB,KAAJ,CAAU,qBAAV,CAAD,EAAmC,kBAAnC,CAAb;AACD;;AAED,YAAIF,OAAO,CAACa,QAAZ,EAAsB;AACpBD,UAAAA,IAAI,CAACG,IAAL;AACE;AACZ;AACA;AACY,2BAAkBa,MAAlB,EAA0B;AACxB,kBAAMC,GAAG,GAAG,MAAMpC,QAAQ,CAACmC,MAAD,CAA1B;AAEA,kBAAMpC,IAAI,CAACsC,IAAL,CAAUD,GAAV,EAAe;AACnBE,cAAAA,KAAK,EAAE/B,OAAO,CAACC,gBAAR,IAA4BP;AADhB,aAAf,CAAN;AAGD,WAVH;AAYD;AACF,OA1D4B,CA4D7B;;;AACA,aAAQH,IAAI,CAAC,GAAGqB,IAAJ,CAAZ;AAEA;AACD;;AAED,UAAM1B,OAAO,CAAC,IAAIgB,KAAJ,CAAU,mBAAV,CAAD,EAAiC,gBAAjC,CAAb;AACD;;AAED,SAAOd,iBAAiB,CAACU,GAAD,CAAxB;AACD","sourcesContent":["import { exporter, recursive } from 'ipfs-unixfs-exporter'\nimport errCode from 'err-code'\nimport { normalizeCidPath } from '../utils.js'\nimport { withTimeoutOption } from 'ipfs-core-utils/with-timeout-option'\nimport { CID } from 'multiformats/cid'\nimport { pack } from 'it-tar'\nimport { pipe } from 'it-pipe'\nimport Pako from 'pako'\nimport toBuffer from 'it-to-buffer'\n\n// https://www.gnu.org/software/gzip/manual/gzip.html\nconst DEFAULT_COMPRESSION_LEVEL = 6\n\n/**\n * @typedef {object} Context\n * @property {import('ipfs-repo').IPFSRepo} repo\n * @property {import('../types').Preload} preload\n *\n * @param {Context} context\n */\nexport function createGet ({ repo, preload }) {\n  /**\n   * @type {import('ipfs-core-types/src/root').API<{}>[\"get\"]}\n   */\n  async function * get (ipfsPath, options = {}) {\n    if (options.compressionLevel != null && (options.compressionLevel < -1 || options.compressionLevel > 9)) {\n      throw errCode(new Error('Compression level must be between -1 and 9'), 'ERR_INVALID_PARAMS')\n    }\n\n    if (options.preload !== false) {\n      let pathComponents\n\n      try {\n        pathComponents = normalizeCidPath(ipfsPath).split('/')\n      } catch (/** @type {any} */ err) {\n        throw errCode(err, 'ERR_INVALID_PATH')\n      }\n\n      preload(CID.parse(pathComponents[0]))\n    }\n\n    const ipfsPathOrCid = CID.asCID(ipfsPath) || ipfsPath\n    const file = await exporter(ipfsPathOrCid, repo.blocks, options)\n\n    if (file.type === 'file' || file.type === 'raw') {\n      const args = []\n\n      if (!options.compress || options.archive === true) {\n        args.push([{\n          header: {\n            name: file.path,\n            mode: file.type === 'file' && file.unixfs.mode,\n            mtime: file.type === 'file' && file.unixfs.mtime ? new Date(file.unixfs.mtime.secs * 1000) : undefined,\n            size: file.size,\n            type: 'file'\n          },\n          body: file.content()\n        }],\n        pack()\n        )\n      } else {\n        args.push(\n          file.content\n        )\n      }\n\n      if (options.compress) {\n        args.push(\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          async function * (source) {\n            const buf = await toBuffer(source)\n\n            yield Pako.gzip(buf, {\n              level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n            })\n          }\n        )\n      }\n\n      // @ts-expect-error cannot derive type\n      yield * pipe(...args)\n\n      return\n    }\n\n    if (file.type === 'directory') {\n      /** @type {any[]} */\n      const args = [\n        recursive(ipfsPathOrCid, repo.blocks, options),\n        /**\n         * @param {AsyncIterable<import('ipfs-unixfs-exporter').UnixFSEntry>} source\n         */\n        async function * (source) {\n          for await (const entry of source) {\n            /** @type {import('it-tar').TarImportCandidate} */\n            const output = {\n              header: {\n                name: entry.path,\n                size: entry.size\n              }\n            }\n\n            if (entry.type === 'file') {\n              output.header.type = 'file'\n              output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined\n              output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined\n              output.body = entry.content()\n            } else if (entry.type === 'raw') {\n              output.header.type = 'file'\n              output.body = entry.content()\n            } else if (entry.type === 'directory') {\n              output.header.type = 'directory'\n              output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined\n              output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined\n            } else {\n              throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS')\n            }\n\n            yield output\n          }\n        },\n        pack()\n      ]\n\n      if (options.compress) {\n        if (!options.archive) {\n          throw errCode(new Error('file is not regular'), 'ERR_INVALID_PATH')\n        }\n\n        if (options.compress) {\n          args.push(\n            /**\n             * @param {AsyncIterable<Uint8Array>} source\n             */\n            async function * (source) {\n              const buf = await toBuffer(source)\n\n              yield Pako.gzip(buf, {\n                level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n              })\n            }\n          )\n        }\n      }\n\n      // @ts-expect-error cannot derive type\n      yield * pipe(...args)\n\n      return\n    }\n\n    throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS')\n  }\n\n  return withTimeoutOption(get)\n}\n"]},"metadata":{},"sourceType":"module"}