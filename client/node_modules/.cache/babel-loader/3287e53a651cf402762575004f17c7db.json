{"ast":null,"code":"import { encode, prepare } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport { createHAMT, Bucket } from 'hamt-sharding';\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n */\n\n/**\n * @typedef {import('./dir').DirProps} DirProps\n */\n\nclass DirSharded extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor(props, options) {\n    super(props, options);\n    /** @type {Bucket<InProgressImportResult | Dir>} */\n\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  /**\n   * @param {string} name\n   */\n\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n\n\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield { ...entry,\n        path: this.path\n      };\n    }\n  }\n\n}\n\nexport default DirSharded;\n/**\n * @param {Bucket<?>} bucket\n * @param {Blockstore} blockstore\n * @param {*} shardRoot\n * @param {ImporterOptions} options\n * @returns {AsyncIterable<ImportResult>}\n */\n\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (child instanceof Bucket) {\n      let shard;\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  } // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n\n\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = encode(prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}","map":{"version":3,"sources":["C:/Users/Akshay Mishra/OneDrive/Desktop/twitter-clone-dapp/node_modules/ipfs-unixfs-importer/src/dir-sharded.js"],"names":["encode","prepare","UnixFS","Dir","persist","createHAMT","Bucket","DirSharded","constructor","props","options","_bucket","hashFn","hamtHashFn","bits","hamtBucketBits","put","name","value","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","key","eachLeafSeries","child","flush","blockstore","entry","path","bucket","shardRoot","children","_children","links","childrenSize","i","length","labelPrefix","toString","toUpperCase","padStart","shard","subShard","Error","push","Name","Tsize","size","Hash","cid","dir","flushedDir","label","data","Uint8Array","from","bitField","reverse","type","fanout","tableSize","hashType","hamtHashCode","mtime","mode","node","Data","marshal","Links","buffer","unixfs"],"mappings":"AAAA,SAASA,MAAT,EAAiBC,OAAjB,QAAgC,cAAhC;AACA,SAASC,MAAT,QAAuB,aAAvB;AACA,OAAOC,GAAP,MAAgB,UAAhB;AACA,OAAOC,OAAP,MAAoB,oBAApB;AACA,SAASC,UAAT,EAAqBC,MAArB,QAAmC,eAAnC;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,MAAMC,UAAN,SAAyBJ,GAAzB,CAA6B;AAC3B;AACF;AACA;AACA;AACEK,EAAAA,WAAW,CAAEC,KAAF,EAASC,OAAT,EAAkB;AAC3B,UAAMD,KAAN,EAAaC,OAAb;AAEA;;AACA,SAAKC,OAAL,GAAeN,UAAU,CAAC;AACxBO,MAAAA,MAAM,EAAEF,OAAO,CAACG,UADQ;AAExBC,MAAAA,IAAI,EAAEJ,OAAO,CAACK;AAFU,KAAD,CAAzB;AAID;AAED;AACF;AACA;AACA;;;AACW,QAAHC,GAAG,CAAEC,IAAF,EAAQC,KAAR,EAAe;AACtB,UAAM,KAAKP,OAAL,CAAaK,GAAb,CAAiBC,IAAjB,EAAuBC,KAAvB,CAAN;AACD;AAED;AACF;AACA;;;AACEC,EAAAA,GAAG,CAAEF,IAAF,EAAQ;AACT,WAAO,KAAKN,OAAL,CAAaQ,GAAb,CAAiBF,IAAjB,CAAP;AACD;;AAEDG,EAAAA,UAAU,GAAI;AACZ,WAAO,KAAKT,OAAL,CAAaU,SAAb,EAAP;AACD;;AAEDC,EAAAA,mBAAmB,GAAI;AACrB,WAAO,KAAKX,OAAL,CAAaY,aAAb,EAAP;AACD;;AAEDC,EAAAA,SAAS,GAAI;AACX,WAAO,KAAKb,OAAL,CAAaa,SAAb,EAAP;AACD;;AAEsB,SAAfC,eAAe,GAAI;AACzB,eAAW,MAAM;AAAEC,MAAAA,GAAF;AAAOR,MAAAA;AAAP,KAAjB,IAAmC,KAAKP,OAAL,CAAagB,cAAb,EAAnC,EAAkE;AAChE,YAAM;AACJD,QAAAA,GADI;AAEJE,QAAAA,KAAK,EAAEV;AAFH,OAAN;AAID;AACF;AAED;AACF;AACA;AACA;;;AACe,SAALW,KAAK,CAAEC,UAAF,EAAc;AACzB,eAAW,MAAMC,KAAjB,IAA0BF,KAAK,CAAC,KAAKlB,OAAN,EAAemB,UAAf,EAA2B,IAA3B,EAAiC,KAAKpB,OAAtC,CAA/B,EAA+E;AAC7E,YAAM,EACJ,GAAGqB,KADC;AAEJC,QAAAA,IAAI,EAAE,KAAKA;AAFP,OAAN;AAID;AACF;;AA9D0B;;AAiE7B,eAAezB,UAAf;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,gBAAiBsB,KAAjB,CAAwBI,MAAxB,EAAgCH,UAAhC,EAA4CI,SAA5C,EAAuDxB,OAAvD,EAAgE;AAC9D,QAAMyB,QAAQ,GAAGF,MAAM,CAACG,SAAxB;AACA,QAAMC,KAAK,GAAG,EAAd;AACA,MAAIC,YAAY,GAAG,CAAnB;;AAEA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,QAAQ,CAACK,MAA7B,EAAqCD,CAAC,EAAtC,EAA0C;AACxC,UAAMX,KAAK,GAAGO,QAAQ,CAAChB,GAAT,CAAaoB,CAAb,CAAd;;AAEA,QAAI,CAACX,KAAL,EAAY;AACV;AACD;;AAED,UAAMa,WAAW,GAAGF,CAAC,CAACG,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AAEA,QAAIhB,KAAK,YAAYtB,MAArB,EAA6B;AAC3B,UAAIuC,KAAJ;;AAEA,iBAAW,MAAMC,QAAjB,IAA6B,MAAMjB,KAAK,CAACD,KAAD,EAAQE,UAAR,EAAoB,IAApB,EAA0BpB,OAA1B,CAAxC,EAA4E;AAC1EmC,QAAAA,KAAK,GAAGC,QAAR;AACD;;AAED,UAAI,CAACD,KAAL,EAAY;AACV,cAAM,IAAIE,KAAJ,CAAU,sDAAV,CAAN;AACD;;AAEDV,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAER,WADG;AAETS,QAAAA,KAAK,EAAEL,KAAK,CAACM,IAFJ;AAGTC,QAAAA,IAAI,EAAEP,KAAK,CAACQ;AAHH,OAAX;AAKAf,MAAAA,YAAY,IAAIO,KAAK,CAACM,IAAtB;AACD,KAjBD,MAiBO,IAAI,OAAOvB,KAAK,CAACV,KAAN,CAAYW,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,YAAMyB,GAAG,GAAG1B,KAAK,CAACV,KAAlB;AACA,UAAIqC,UAAJ;;AAEA,iBAAW,MAAMxB,KAAjB,IAA0BuB,GAAG,CAACzB,KAAJ,CAAUC,UAAV,CAA1B,EAAiD;AAC/CyB,QAAAA,UAAU,GAAGxB,KAAb;AAEA,cAAMwB,UAAN;AACD;;AAED,YAAMC,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACAW,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEO,KADG;AAETN,QAAAA,KAAK,EAAEK,UAAU,CAACJ,IAFT;AAGTC,QAAAA,IAAI,EAAEG,UAAU,CAACF;AAHR,OAAX;AAMAf,MAAAA,YAAY,IAAIiB,UAAU,CAACJ,IAA3B;AACD,KAlBM,MAkBA;AACL,YAAMjC,KAAK,GAAGU,KAAK,CAACV,KAApB;;AAEA,UAAI,CAACA,KAAK,CAACmC,GAAX,EAAgB;AACd;AACD;;AAED,YAAMG,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACA,YAAMyB,IAAI,GAAGjC,KAAK,CAACiC,IAAnB;AAEAd,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEO,KADG;AAETN,QAAAA,KAAK,EAAEC,IAFE;AAGTC,QAAAA,IAAI,EAAElC,KAAK,CAACmC;AAHH,OAAX;AAKAf,MAAAA,YAAY,IAAIa,IAAhB;AACD;AACF,GAlE6D,CAoE9D;AACA;;;AACA,QAAMM,IAAI,GAAGC,UAAU,CAACC,IAAX,CAAgBxB,QAAQ,CAACyB,QAAT,GAAoBC,OAApB,EAAhB,CAAb;AACA,QAAMP,GAAG,GAAG,IAAIpD,MAAJ,CAAW;AACrB4D,IAAAA,IAAI,EAAE,wBADe;AAErBL,IAAAA,IAFqB;AAGrBM,IAAAA,MAAM,EAAE9B,MAAM,CAAC+B,SAAP,EAHa;AAIrBC,IAAAA,QAAQ,EAAEvD,OAAO,CAACwD,YAJG;AAKrBC,IAAAA,KAAK,EAAEjC,SAAS,IAAIA,SAAS,CAACiC,KALT;AAMrBC,IAAAA,IAAI,EAAElC,SAAS,IAAIA,SAAS,CAACkC;AANR,GAAX,CAAZ;AASA,QAAMC,IAAI,GAAG;AACXC,IAAAA,IAAI,EAAEhB,GAAG,CAACiB,OAAJ,EADK;AAEXC,IAAAA,KAAK,EAAEnC;AAFI,GAAb;AAIA,QAAMoC,MAAM,GAAGzE,MAAM,CAACC,OAAO,CAACoE,IAAD,CAAR,CAArB;AACA,QAAMhB,GAAG,GAAG,MAAMjD,OAAO,CAACqE,MAAD,EAAS3C,UAAT,EAAqBpB,OAArB,CAAzB;AACA,QAAMyC,IAAI,GAAGsB,MAAM,CAACjC,MAAP,GAAgBF,YAA7B;AAEA,QAAM;AACJe,IAAAA,GADI;AAEJqB,IAAAA,MAAM,EAAEpB,GAFJ;AAGJH,IAAAA;AAHI,GAAN;AAKD","sourcesContent":["import { encode, prepare } from '@ipld/dag-pb'\nimport { UnixFS } from 'ipfs-unixfs'\nimport Dir from './dir.js'\nimport persist from './utils/persist.js'\nimport { createHAMT, Bucket } from 'hamt-sharding'\n\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n */\n\n/**\n * @typedef {import('./dir').DirProps} DirProps\n */\n\nclass DirSharded extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor (props, options) {\n    super(props, options)\n\n    /** @type {Bucket<InProgressImportResult | Dir>} */\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    })\n  }\n\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n  async put (name, value) {\n    await this._bucket.put(name, value)\n  }\n\n  /**\n   * @param {string} name\n   */\n  get (name) {\n    return this._bucket.get(name)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild () {\n    return this._bucket.onlyChild()\n  }\n\n  async * eachChildSeries () {\n    for await (const { key, value } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      }\n    }\n  }\n\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n  async * flush (blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      }\n    }\n  }\n}\n\nexport default DirSharded\n\n/**\n * @param {Bucket<?>} bucket\n * @param {Blockstore} blockstore\n * @param {*} shardRoot\n * @param {ImporterOptions} options\n * @returns {AsyncIterable<ImportResult>}\n */\nasync function * flush (bucket, blockstore, shardRoot, options) {\n  const children = bucket._children\n  const links = []\n  let childrenSize = 0\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i)\n\n    if (!child) {\n      continue\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0')\n\n    if (child instanceof Bucket) {\n      let shard\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found')\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      })\n      childrenSize += shard.size\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value\n      let flushedDir\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry\n\n        yield flushedDir\n      }\n\n      const label = labelPrefix + child.key\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      })\n\n      childrenSize += flushedDir.size\n    } else {\n      const value = child.value\n\n      if (!value.cid) {\n        continue\n      }\n\n      const label = labelPrefix + child.key\n      const size = value.size\n\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      })\n      childrenSize += size\n    }\n  }\n\n  // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n  const data = Uint8Array.from(children.bitField().reverse())\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  })\n\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  }\n  const buffer = encode(prepare(node))\n  const cid = await persist(buffer, blockstore, options)\n  const size = buffer.length + childrenSize\n\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  }\n}\n"]},"metadata":{},"sourceType":"module"}